# Requires Python 3.10
--extra-index-url https://download.pytorch.org/whl/cu121

torch==2.1.2+cu121

# flash-attn build/runtime prerequisites
numpy<2
setuptools<81
wheel
psutil
packaging
ninja

shortuuid
datasets
httpx[socks]
huggingface_hub

# Install flash-attn separately after torch is installed:
# pip install flash-attn==2.5.8 --no-build-isolation
