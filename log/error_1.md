```bash
test-000020-of-000028.parquet: 100%|█| 144M/144M [00:14<00:00, 9.89MB/
Downloading data:  50%|██████      | 14/28 [03:45<03:56, 16.90s/files[INFO] Dataset loading in progress ... elapsed=240s[00:08<00:05, 10.2MB
test-000021-of-000028.parquet: 100%|█| 139M/139M [00:13<00:00, 10.2MB/
Downloading data:  54%|██████▍     | 15/28 [04:00<03:29, 16.09s/files[INFO] Dataset loading in progress ... elapsed=250s[00:02<00:11, 10.8MB
                                                                     [INFO] Dataset loading in progress ... elapsed=260s00:13<00:02, 10.4MB/
test-000022-of-000028.parquet: 100%|█| 157M/157M [00:15<00:00, 9.94MB/
Downloading data:  57%|██████▊     | 16/28 [04:16<03:14, 16.20s/files[INFO] Dataset loading in progress ... elapsed=270s[00:07<00:09, 10.5MB
test-000023-of-000028.parquet: 100%|█| 170M/170M [00:16<00:00, 10.1MB/
Downloading data:  61%|███████▎    | 17/28 [04:34<03:02, 16.58s/files[INFO] Dataset loading in progress ... elapsed=280s200M [00:00<?, ?B/s]
                                                                     [INFO] Dataset loading in progress ... elapsed=290s[00:09<00:10, 10.2MB
                                                                     [INFO] Dataset loading in progress ... elapsed=300s00:20<00:00, 10.3MB/
test-000024-of-000028.parquet: 100%|█| 200M/200M [00:20<00:00, 9.94MB/
Downloading data:  64%|███████▋    | 18/28 [04:54<02:58, 17.85s/files[INFO] Dataset loading in progress ... elapsed=310s[00:08<00:08, 10.5MB
test-000025-of-000028.parquet: 100%|█| 175M/175M [00:17<00:00, 10.1MB/
Downloading data:  68%|████████▏   | 19/28 [05:12<02:41, 17.90s/files[INFO] Dataset loading in progress ... elapsed=320s149M [00:00<?, ?B/s]
                                                                     [INFO] Dataset loading in progress ... elapsed=330s00:10<00:04, 10.3MB/                    ages, modalities, image_sizes
test-000026-of-000028.parquet: 100%|█| 149M/149M [00:15<00:00, 9.78MB/
test-000027-of-000028.parquet: 100%|█| 14.9M/14.9M [00:01<00:00, 10.1M
Downloading data:  75%|█████████   | 21/28 [05:31<01:30, 12.89s/files[INFO] Dataset loading in progress ... elapsed=340s00:01<00:31, 6.37MB/
                                                                     [INFO] Dataset loading in progress ... elapsed=350s0:12<00:09, 10.2MB/s
test-00003-of-000028.parquet: 100%|█| 211M/211M [00:21<00:00, 9.67MB/s
Downloading data:  79%|█████████▍  | 22/28 [05:54<01:35, 15.85s/files][INFO] Dataset loading in progress ... elapsed=360s
                                                                     [INFO] Dataset loading in progress ... elapsed=370s00:09<00:01, 10.3MB/
test-00004-of-000028.parquet: 100%|█| 109M/109M [00:10<00:00, 10.2MB/s
Downloading data:  82%|█████████▊  | 23/28 [06:05<01:12, 14.55s/files[INFO] Dataset loading in progress ... elapsed=380s00:07<00:09, 9.40MB/
test-00005-of-000028.parquet: 100%|█| 155M/155M [00:16<00:00, 9.54MB/s
Downloading data:  86%|██████████▎ | 24/28 [06:23<01:01, 15.36s/files[INFO] Dataset loading in progress ... elapsed=390s162M [00:00<?, ?B/s]
                                                                     [INFO] Dataset loading in progress ... elapsed=400s0:10<00:05, 10.3MB/s
test-00006-of-000028.parquet: 100%|█| 162M/162M [00:16<00:00, 10.1MB/s
Downloading data:  89%|██████████▋ | 25/28 [06:39<00:47, 15.79s/files[INFO] Dataset loading in progress ... elapsed=410s00:03<00:13, 9.41MB/
                                                                     [INFO] Dataset loading in progress ... elapsed=420s0:13<00:01, 10.5MB/s
test-00007-of-000028.parquet: 100%|█| 157M/157M [00:15<00:00, 9.91MB/s
Downloading data:  93%|███████████▏| 26/28 [06:56<00:32, 16.10s/files[INFO] Dataset loading in progress ... elapsed=430s00:06<00:14, 9.85MB/
                                                                     [INFO] Dataset loading in progress ... elapsed=440s0:17<00:04, 10.3MB/s
test-00008-of-000028.parquet: 100%|█| 210M/210M [00:21<00:00, 9.87MB/s
Downloading data:  96%|███████████▌| 27/28 [07:18<00:17, 17.89s/files[INFO] Dataset loading in progress ... elapsed=450s00:04<00:11, 10.2MB/
                                                                     [INFO] Dataset loading in progress ... elapsed=460s0:14<00:01, 9.78MB/s
test-00009-of-000028.parquet: 100%|█| 159M/159M [00:15<00:00, 10.0MB/s
Downloading data: 100%|████████████| 28/28 [07:35<00:00, 16.27s/files]
Generating test split:  11%| | 150/1353 [00:08<01:07, 17.84 examples/s[INFO] Dataset loading in progress ... elapsed=470s
Generating test split:  22%|▏| 300/1353 [00:16<00:57, 18.46 examples/s[INFO] Dataset loading in progress ... elapsed=480s
Generating test split:  37%|▎| 500/1353 [00:28<00:51, 16.69 examples/s[INFO] Dataset loading in progress ... elapsed=490s
Generating test split:  48%|▍| 650/1353 [00:38<00:45, 15.59 examples/s[INFO] Dataset loading in progress ... elapsed=500s
Generating test split:  59%|▌| 800/1353 [00:46<00:31, 17.49 examples/s[INFO] Dataset loading in progress ... elapsed=510s
Generating test split:  70%|▋| 950/1353 [00:56<00:26, 15.12 examples/s[INFO] Dataset loading in progress ... elapsed=520s
Generating test split:  82%|▊| 1103/1353 [01:06<00:16, 15.60 examples/[INFO] Dataset loading in progress ... elapsed=530s
Generating test split:  93%|▉| 1253/1353 [01:16<00:06, 16.10 examples/[INFO] Dataset loading in progress ... elapsed=540s
Generating test split: 100%|█| 1353/1353 [01:23<00:00, 16.17 examples/
[INFO] Dataset loaded in 545.5s
[INFO] Dataset ready. total=1353
[INFO] Fetching first sample...
[INFO] First sample fetched. Starting evaluation.
MRAG-Bench Eval:   0%| | 0/1353 [00:02<?, ?sample/s, stage=generate, s
Traceback (most recent call last):
  File "/home/user/code/mRAG/github/MRAG-Bench/eval/models/llava_one_vision.py", line 158, in <module>
    eval_model(args)
  File "/home/user/code/mRAG/github/MRAG-Bench/eval/models/llava_one_vision.py", line 92, in eval_model
    cont = model.generate(
  File "/home/user/env/envs/llava/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/user/code/mRAG/github/LLaVA-NeXT/llava/model/language_model/llava_qwen.py", line 131, in generate
    (inputs, position_ids, attention_mask, _, inputs_embeds, _) = self.prepare_inputs_labels_for_multimodal(inputs, position_ids, attention_mask, None, None, images, modalities, image_sizes=image_sizes)
  File "/home/user/code/mRAG/github/LLaVA-NeXT/llava/model/llava_arch.py", line 288, in prepare_inputs_labels_for_multimodal
    encoded_image_features = self.encode_images(concat_images)
  File "/home/user/code/mRAG/github/LLaVA-NeXT/llava/model/llava_arch.py", line 202, in encode_images                                                           98856f-df92-" 22:12 12-2月-26
    image_features = self.get_model().get_vision_tower()(images)
  File "/home/user/env/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/user/env/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/user/code/mRAG/github/LLaVA-NeXT/llava/model/multimodal_encoder/siglip_encoder.py", line 601, in forward
    image_forward_outs = self.vision_tower(images.to(device=self.device, dtype=self.dtype), output_hidden_states=True)
  File "/home/user/env/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/user/env/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/user/code/mRAG/github/LLaVA-NeXT/llava/model/multimodal_encoder/siglip_encoder.py", line 540, in forward
    return self.vision_model(
  File "/home/user/env/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/user/env/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/user/code/mRAG/github/LLaVA-NeXT/llava/model/multimodal_encoder/siglip_encoder.py", line 446, in forward
    encoder_outputs = self.encoder(
  File "/home/user/env/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/user/env/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/user/code/mRAG/github/LLaVA-NeXT/llava/model/multimodal_encoder/siglip_encoder.py", line 399, in forward
    layer_outputs = encoder_layer(
  File "/home/user/env/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/user/env/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/user/code/mRAG/github/LLaVA-NeXT/llava/model/multimodal_encoder/siglip_encoder.py", line 298, in forward
    hidden_states, attn_weights = self.self_attn(
  File "/home/user/env/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/user/env/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/user/code/mRAG/github/LLaVA-NeXT/llava/model/multimodal_encoder/siglip_encoder.py", line 217, in forward
    query_states = self.q_proj(hidden_states)
  File "/home/user/env/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/user/env/envs/llava/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/user/env/envs/llava/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_INTERNAL_ERROR when calling `cublasCreate(handle)`
```